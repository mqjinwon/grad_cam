{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference baseline code\n",
    "https://github.com/Caoliangjie/pytorch-gradcam-resnet50/blob/bfbd6d2fa6f6c490eaba1232b226ca4b09fe5fc1/grad-cam.py#L80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pretrained model\n",
    "### every models are pre-trained 1000-class Imagenet datasets\n",
    "### reference: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"cat.jpg\"\n",
    "MODEL_NAME = \"resnet18\"\n",
    "TARGET_CLASS = 1 # None is highest confidence\n",
    "TARGET_LAYER_NAMES = [\"layer4\"]\n",
    "\n",
    "IMAGE_SIZE = (224,224)  # later, automatically determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "torch version: 1.8.0+cu111\n",
      "cuda available: True\n",
      "==========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get pretrained model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "print(\"==========================================\")\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"cuda available: {torch.cuda.is_available()}\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# load pretrained model\n",
    "if MODEL_NAME == \"resnet18\":\n",
    "    model = models.resnet18(pretrained=True, progress=True)\n",
    "if MODEL_NAME == \"resnet50\":\n",
    "    model = models.resnet50(pretrained=True, progress=True)\n",
    "\n",
    "model.eval()\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test whether it works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1, 3, 64, 64).to(device) # you need to select input size of the model\n",
    "labels = torch.rand(1, 1000).to(device) # you need to select the class you want to predict\n",
    "\n",
    "prediction = model(data)\n",
    "\n",
    "loss = (prediction - labels).sum()\n",
    "loss.backward() # backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image for testing\n",
    "### preprocess image to be fitted pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# normalized image\n",
    "origin_img = cv2.imread(IMG_PATH, 1)\n",
    "rgb_img = np.float32(origin_img) / 255\n",
    "\n",
    "IMAGE_SIZE = (rgb_img.shape[0], rgb_img.shape[1]) # determine image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "image_transformer = Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "input_tensor = image_transformer(rgb_img).unsqueeze(0).to(device)\n",
    "input_tensor.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Grad-CAM\n",
    "## -Extract gradient\n",
    "### using gradient hook, get gradient layers what we want\n",
    "\n",
    "## -GradCAM\n",
    "### Wrapping extract gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractGradient():\n",
    "    def __init__(self, model, target_layers, device = 'cpu'):\n",
    "\n",
    "        # gradientì ì¥í  ë³ì ì§ì \n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "        \n",
    "        self.target_layers = target_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.gradients = []\n",
    "\n",
    "        print(\"============Module name============\")\n",
    "        for name, module in self.model._modules.items():\n",
    "            print(name)\n",
    "            if name in self.target_layers:\n",
    "                print(\"register hook\")\n",
    "                module.register_full_backward_hook(self.gradient_hook_function)\n",
    "\n",
    "        print(\"===================================\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    # Implement hookup function\n",
    "    def gradient_hook_function(self, module, grad_in, grad_out):\n",
    "        # grad_in : [batch_size, num_features, height, width]        \n",
    "        self.gradients.append(grad_in[0])   # No need batch\n",
    "\n",
    "    # get backwards gradient\n",
    "    def backward_gradient(self, output, target_label):\n",
    "\n",
    "        # make target label's one-hot vector\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype = np.float32)\n",
    "        one_hot[0][target_label] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).to(self.device)\n",
    "        one_hot.requires_grad = True\n",
    "\n",
    "        one_hot = torch.sum(one_hot * output)\n",
    "        \n",
    "        # hookup function ë°ë\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "    def get_gradient(self):\n",
    "\n",
    "        output = self.gradients\n",
    "        self.gradients = []\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCam(ExtractGradient):\n",
    "    def __init__(self, model, target_layers, device = 'cpu'):\n",
    "\n",
    "        super().__init__(model, target_layers, device)\n",
    "\n",
    "    def make_grad_cam_image(self, gradients, image_size=(224,224)):\n",
    "\n",
    "        grad_cam_image = np.zeros(image_size, dtype=np.float32)\n",
    "\n",
    "        for cam in gradients:\n",
    "\n",
    "            cam = cam.cpu().data.numpy().squeeze(axis=0) # [num_features, height, width]\n",
    "            weights = np.mean(cam, axis=(1,2))\n",
    "\n",
    "            tmp_grad = np.zeros_like(cam[0,:,:])\n",
    "\n",
    "            for i, w in enumerate(weights):\n",
    "                tmp_grad += w * cam[i, :, :]\n",
    "\n",
    "            tmp_grad = cv2.resize(tmp_grad, (image_size[1],image_size[0]))\n",
    "\n",
    "            grad_cam_image += tmp_grad\n",
    "            \n",
    "        \n",
    "        grad_cam_image = np.maximum(grad_cam_image, 0)  # like relu\n",
    "        \n",
    "        ## normalize\n",
    "        grad_cam_image = grad_cam_image - np.min(grad_cam_image)\n",
    "        grad_cam_image = grad_cam_image / (1e-7 + np.max(grad_cam_image)) # prevent from zero division\n",
    "\n",
    "        return grad_cam_image\n",
    "    \n",
    "    def __call__(self, x, target_label=None):\n",
    "\n",
    "        # forward pass\n",
    "        prediction = self.forward(x)\n",
    "\n",
    "        # make gradient\n",
    "        if target_label is None:\n",
    "            target_label = np.argmax(prediction.cpu().data.numpy())\n",
    "\n",
    "        print(f\"target label: {target_label}\")\n",
    "\n",
    "        self.backward_gradient(prediction, target_label)\n",
    "\n",
    "        # get gradient\n",
    "        gradients = self.get_gradient()\n",
    "\n",
    "        # make grad cam image\n",
    "        grad_cam_image = self.make_grad_cam_image(gradients, image_size=IMAGE_SIZE)\n",
    "\n",
    "        return grad_cam_image, target_label, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Module name============\n",
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n",
      "register hook\n",
      "avgpool\n",
      "fc\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "import copy # gpu make error, so copying but it doesn't work\n",
    "grad_cam = GradCam(copy.deepcopy(model), TARGET_LAYER_NAMES, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target label: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\nYou can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\n\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.allow_tf32 = True\ndata = torch.randn([1, 64, 102, 153], dtype=torch.float, device='cuda', requires_grad=True)\nnet = torch.nn.Conv2d(64, 64, kernel_size=[3, 3], padding=[1, 1], stride=[1, 1], dilation=[1, 1], groups=1)\nnet = net.cuda().float()\nout = net(data)\nout.backward(torch.randn_like(out))\ntorch.cuda.synchronize()\n\nConvolutionParams \n    data_type = CUDNN_DATA_FLOAT\n    padding = [1, 1, 0]\n    stride = [1, 1, 0]\n    dilation = [1, 1, 0]\n    groups = 1\n    deterministic = false\n    allow_tf32 = true\ninput: TensorDescriptor 0x7f39a80ecde0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 1, 64, 102, 153, \n    strideA = 998784, 15606, 153, 1, \noutput: TensorDescriptor 0x7f39a80e9d30\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 1, 64, 102, 153, \n    strideA = 998784, 15606, 153, 1, \nweight: FilterDescriptor 0x7f39a80e36e0\n    type = CUDNN_DATA_FLOAT\n    tensor_format = CUDNN_TENSOR_NCHW\n    nbDims = 4\n    dimA = 64, 64, 3, 3, \nPointer addresses: \n    input: 0xb2c43d800\n    output: 0xb320cf600\n    weight: 0xb31cb0000\nAdditional pointer addresses: \n    grad_output: 0xb320cf600\n    grad_weight: 0xb31cb0000\nBackward filter algorithm: 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1605/896204982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrad_cam_iamge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTARGET_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1605/4073260471.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, target_label)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"target label: {target_label}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# get gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1605/1855724719.py\u001b[0m in \u001b[0;36mbackward_gradient\u001b[0;34m(self, output, target_label)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# hookup function ë°ë\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\nYou can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\n\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.allow_tf32 = True\ndata = torch.randn([1, 64, 102, 153], dtype=torch.float, device='cuda', requires_grad=True)\nnet = torch.nn.Conv2d(64, 64, kernel_size=[3, 3], padding=[1, 1], stride=[1, 1], dilation=[1, 1], groups=1)\nnet = net.cuda().float()\nout = net(data)\nout.backward(torch.randn_like(out))\ntorch.cuda.synchronize()\n\nConvolutionParams \n    data_type = CUDNN_DATA_FLOAT\n    padding = [1, 1, 0]\n    stride = [1, 1, 0]\n    dilation = [1, 1, 0]\n    groups = 1\n    deterministic = false\n    allow_tf32 = true\ninput: TensorDescriptor 0x7f39a80ecde0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 1, 64, 102, 153, \n    strideA = 998784, 15606, 153, 1, \noutput: TensorDescriptor 0x7f39a80e9d30\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 1, 64, 102, 153, \n    strideA = 998784, 15606, 153, 1, \nweight: FilterDescriptor 0x7f39a80e36e0\n    type = CUDNN_DATA_FLOAT\n    tensor_format = CUDNN_TENSOR_NCHW\n    nbDims = 4\n    dimA = 64, 64, 3, 3, \nPointer addresses: \n    input: 0xb2c43d800\n    output: 0xb320cf600\n    weight: 0xb31cb0000\nAdditional pointer addresses: \n    grad_output: 0xb320cf600\n    grad_weight: 0xb31cb0000\nBackward filter algorithm: 5\n"
     ]
    }
   ],
   "source": [
    "grad_cam_iamge, target_label, gradients = grad_cam(input_tensor, TARGET_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_cam_iamge shape: (408, 612)\n",
      "grad_cam_iamge min: 0.0\n",
      "grad_cam_iamge max: 0.9996618032455444\n",
      "grad_np shape: (1, 256, 26, 39)\n",
      "grad_np min: -0.025650158524513245\n",
      "grad_np max: 0.027240999042987823\n"
     ]
    }
   ],
   "source": [
    "print(f\"grad_cam_iamge shape: {grad_cam_iamge.shape}\")\n",
    "print(f\"grad_cam_iamge min: {grad_cam_iamge.min()}\")\n",
    "print(f\"grad_cam_iamge max: {grad_cam_iamge.max()}\")\n",
    "\n",
    "grad_np = gradients[0].cpu().data.numpy()\n",
    "print(f\"grad_np shape: {grad_np.shape}\")\n",
    "print(f\"grad_np min: {grad_np.min()}\")\n",
    "print(f\"grad_np max: {grad_np.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get imagenet labels\n",
    "### reference: https://discuss.pytorch.org/t/imagenet-classes/4923/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class_idx = json.load(open(\"imagenet_class_index.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam_on_image(img: np.ndarray,\n",
    "                      mask: np.ndarray,\n",
    "                      use_rgb: bool = False,\n",
    "                      colormap: int = cv2.COLORMAP_JET) -> np.ndarray:\n",
    "    \"\"\" This function overlays the cam mask on the image as an heatmap.\n",
    "    By default the heatmap is in BGR format.\n",
    "\n",
    "    :param img: The base image in RGB or BGR format.\n",
    "    :param mask: The cam mask.\n",
    "    :param use_rgb: Whether to use an RGB or BGR heatmap, this should be set to True if 'img' is in RGB format.\n",
    "    :param colormap: The OpenCV colormap to be used.\n",
    "    :returns: The default image with the cam overlay.\n",
    "    \"\"\"\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), colormap)\n",
    "    if use_rgb:\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "\n",
    "    if np.max(img) > 1:\n",
    "        raise Exception(\n",
    "            \"The input image should np.float32 in the range [0, 1]\")\n",
    "\n",
    "    cam = heatmap + img\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(heatmap*255), np.uint8(255 * cam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target label: 1, goldfish\n"
     ]
    }
   ],
   "source": [
    "heatmap, mix_image = show_cam_on_image(rgb_img, grad_cam_iamge)\n",
    "\n",
    "cv2.imwrite(\"grad_cam_gray.jpg\", np.uint8(grad_cam_iamge*255))\n",
    "cv2.imwrite(\"grad_cam_heatmap.jpg\", heatmap)\n",
    "cv2.imwrite(\"grad_cam_image.jpg\", mix_image)\n",
    "\n",
    "print(f\"target label: {target_label}, {class_idx[str(target_label)][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Backpropagation\n",
    "### using https://github.com/Caoliangjie/pytorch-gradcam-resnet50/blob/bfbd6d2fa6f6c490eaba1232b226ca4b09fe5fc1/grad-cam.py#L80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedBackpropReLUModel:\n",
    "\tdef __init__(self, model, device):\n",
    "\t\tself.model = model\n",
    "\t\tself.model.eval()\n",
    "\t\tself.model.to(device)\n",
    "\n",
    "\t\tself.device = device\n",
    "\n",
    "\t\tfor module in self.model.named_modules():\n",
    "\t\t\tmodule[1].register_backward_hook(self.bp_relu)\n",
    "\n",
    "\tdef bp_relu(self, module, grad_in, grad_out):\n",
    "\t\tif isinstance(module, nn.ReLU):\n",
    "\t\t\treturn (torch.clamp(grad_in[0], min=0.0),)\n",
    "\tdef forward(self, input):\n",
    "\t\treturn self.model(input)\n",
    "\n",
    "\tdef __call__(self, input, index = None):\n",
    "\t\tinput = input.to(self.device)\n",
    "\n",
    "\t\toutput = self.forward(input)\n",
    "\n",
    "\t\tif index == None:\n",
    "\t\t\tindex = np.argmax(output.cpu().data.numpy())\n",
    "\t\tone_hot = np.zeros((1, output.size()[-1]), dtype = np.float32)\n",
    "\t\tone_hot[0][index] = 1\n",
    "\t\tone_hot = torch.from_numpy(one_hot)\n",
    "\t\tone_hot.requires_grad = True\n",
    "\t\tone_hot = one_hot.to(self.device)\n",
    "\n",
    "\t\tone_hot = torch.sum(one_hot * output)\n",
    "\t\tone_hot.backward(retain_graph=True)\n",
    "\t\toutput = input.grad.cpu().data.numpy()\n",
    "\t\toutput = output[0,:,:,:]\n",
    "\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\nYou can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\n\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.allow_tf32 = True\ndata = torch.randn([1, 64, 102, 153], dtype=torch.float, device='cuda', requires_grad=True)\nnet = torch.nn.Conv2d(64, 64, kernel_size=[3, 3], padding=[1, 1], stride=[1, 1], dilation=[1, 1], groups=1)\nnet = net.cuda().float()\nout = net(data)\nout.backward(torch.randn_like(out))\ntorch.cuda.synchronize()\n\nConvolutionParams \n    data_type = CUDNN_DATA_FLOAT\n    padding = [1, 1, 0]\n    stride = [1, 1, 0]\n    dilation = [1, 1, 0]\n    groups = 1\n    deterministic = false\n    allow_tf32 = true\ninput: TensorDescriptor 0x7f39a80e07d0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 1, 64, 102, 153, \n    strideA = 998784, 15606, 153, 1, \noutput: TensorDescriptor 0x7f39a8038ad0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 1, 64, 102, 153, \n    strideA = 998784, 15606, 153, 1, \nweight: FilterDescriptor 0x7f39a80cbbd0\n    type = CUDNN_DATA_FLOAT\n    tensor_format = CUDNN_TENSOR_NCHW\n    nbDims = 4\n    dimA = 64, 64, 3, 3, \nPointer addresses: \n    input: 0xb1f6dec00\n    output: 0xb2552ae00\n    weight: 0xb1ca30000\nAdditional pointer addresses: \n    grad_output: 0xb2552ae00\n    grad_weight: 0xb1ca30000\nBackward filter algorithm: 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1605/1739804201.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGuidedBackpropReLUModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1605/417172623.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input, index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\nYou can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\n\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.allow_tf32 = True\ndata = torch.randn([1, 64, 102, 153], dtype=torch.float, device='cuda', requires_grad=True)\nnet = torch.nn.Conv2d(64, 64, kernel_size=[3, 3], padding=[1, 1], stride=[1, 1], dilation=[1, 1], groups=1)\nnet = net.cuda().float()\nout = net(data)\nout.backward(torch.randn_like(out))\ntorch.cuda.synchronize()\n\nConvolutionParams \n    data_type = CUDNN_DATA_FLOAT\n    padding = [1, 1, 0]\n    stride = [1, 1, 0]\n    dilation = [1, 1, 0]\n    groups = 1\n    deterministic = false\n    allow_tf32 = true\ninput: TensorDescriptor 0x7f39a80e07d0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 1, 64, 102, 153, \n    strideA = 998784, 15606, 153, 1, \noutput: TensorDescriptor 0x7f39a8038ad0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 1, 64, 102, 153, \n    strideA = 998784, 15606, 153, 1, \nweight: FilterDescriptor 0x7f39a80cbbd0\n    type = CUDNN_DATA_FLOAT\n    tensor_format = CUDNN_TENSOR_NCHW\n    nbDims = 4\n    dimA = 64, 64, 3, 3, \nPointer addresses: \n    input: 0xb1f6dec00\n    output: 0xb2552ae00\n    weight: 0xb1ca30000\nAdditional pointer addresses: \n    grad_output: 0xb2552ae00\n    grad_weight: 0xb1ca30000\nBackward filter algorithm: 5\n"
     ]
    }
   ],
   "source": [
    "gb_model = GuidedBackpropReLUModel(model = copy.deepcopy(model), device=device)\n",
    "gb = gb_model(input_tensor, index=TARGET_CLASS)\n",
    "\n",
    "weights = np.mean(gb, axis=(1,2))\n",
    "\n",
    "gb_img = np.zeros_like(gb[0,:,:])\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    gb_img += w * gb[i, :, :]\n",
    "\n",
    "## normalize\n",
    "gb_img = np.maximum(gb_img, 0)\n",
    "gb_img = gb_img - np.min(gb_img)\n",
    "gb_img = gb_img / (1e-7 + np.max(gb_img)) # prevent from zero division\n",
    "\n",
    "cv2.imwrite(\"guided_backpropagation.jpg\", gb_img*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggc = grad_cam_iamge * gb_img\n",
    "ggc = ggc - np.min(ggc)\n",
    "ggc = ggc / (1e-7 + np.max(ggc)) # prevent from zero division\n",
    "\n",
    "cv2.imwrite(\"guided_grad_cam.jpg\", ggc*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7eed93dc45298f775a235f9c8ceab519376a81a51a49db26b184bd97cca2122"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
